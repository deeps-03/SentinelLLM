version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - log-streaming
      
  kafka:
    image: wurstmeister/kafka:2.13-2.8.1
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "logs:1:1,raw-logs:1:1,classified-logs:1:1,anomalies:1:1"
    depends_on:
      - zookeeper
    networks:
      - log-streaming
      
  victoria-metrics:
    image: victoriametrics/victoria-metrics:latest
    ports:
      - "8428:8428"
    volumes:
      - victoria-metrics-data:/victoria-metrics-data
    networks:
      - log-streaming
      
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - victoria-metrics
    networks:
      - log-streaming
      
  log-producer:
    build:
      context: .
      dockerfile: Dockerfile.producer
    command: python log_producer.py
    environment:
      - PYTHONUNBUFFERED=1
    depends_on:
      - kafka
    networks:
      - log-streaming
    environment:
      - KAFKA_BROKER=${KAFKA_BROKER:-kafka:9093}
      
  log-consumer:
    build:
      context: .
      dockerfile: Dockerfile.consumer
    restart: on-failure
    depends_on:
      kafka:
        condition: service_started
      victoria-metrics:
        condition: service_started
      ollama:
        condition: service_started
    networks:
      - log-streaming
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - KAFKA_BROKER=${KAFKA_BROKER:-kafka:9093}
      - RAW_LOGS_TOPIC=${RAW_LOGS_TOPIC:-raw-logs}
      - CLASSIFIED_LOGS_TOPIC=${CLASSIFIED_LOGS_TOPIC:-classified-logs}
      
  anomaly-detector:
    build:
      context: .
      dockerfile: Dockerfile.anomaly_detector
    depends_on:
      - victoria-metrics
    networks:
      - log-streaming
    environment:
      - GRAFANA_API_KEY=${GRAFANA_API_KEY}
      - KAFKA_BROKER=${KAFKA_BROKER:-kafka:9093}
      - ANOMALIES_TOPIC=${ANOMALIES_TOPIC:-anomalies}
      
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    command: ["serve"]
    networks:
      - log-streaming
      
  aws-log-poller:
    build:
      context: .
      dockerfile: Dockerfile.aws_log_poller
    depends_on:
      - kafka
    networks:
      - log-streaming
    volumes:
      - aws-checkpoints:/app/checkpoints
    environment:
      - KAFKA_BROKER=${KAFKA_BROKER:-kafka:9093}
      - RAW_LOGS_TOPIC=${RAW_LOGS_TOPIC:-raw-logs}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION:-us-east-1}
      - AWS_LOG_GROUPS=${AWS_LOG_GROUPS}
      - AWS_POLL_INTERVAL_SECONDS=${AWS_POLL_INTERVAL_SECONDS:-30}
      - MAX_RETRIES=${MAX_RETRIES:-5}
      - RETRY_DELAY_SECONDS=${RETRY_DELAY_SECONDS:-5}
    profiles:
      - aws
      
  azure-log-poller:
    build:
      context: .
      dockerfile: Dockerfile.azure_log_poller
    depends_on:
      - kafka
    networks:
      - log-streaming
    volumes:
      - azure-checkpoints:/app/checkpoints
    environment:
      - KAFKA_BROKER=${KAFKA_BROKER:-kafka:9093}
      - RAW_LOGS_TOPIC=${RAW_LOGS_TOPIC:-raw-logs}
      - AZURE_TENANT_ID=${AZURE_TENANT_ID}
      - AZURE_CLIENT_ID=${AZURE_CLIENT_ID}
      - AZURE_CLIENT_SECRET=${AZURE_CLIENT_SECRET}
      - AZURE_WORKSPACE_ID=${AZURE_WORKSPACE_ID}
      - AZURE_QUERY=${AZURE_QUERY:-union * | where TimeGenerated > ago(1h) | order by TimeGenerated desc | limit 100}
      - AZURE_POLL_INTERVAL_SECONDS=${AZURE_POLL_INTERVAL_SECONDS:-60}
      - MAX_RETRIES=${MAX_RETRIES:-5}
      - RETRY_DELAY_SECONDS=${RETRY_DELAY_SECONDS:-5}
    profiles:
      - azure
      
  notifier:
    build:
      context: .
      dockerfile: Dockerfile.notifier
    depends_on:
      - kafka
    networks:
      - log-streaming
    environment:
      - KAFKA_BROKER=${KAFKA_BROKER:-kafka:9093}
      - CLASSIFIED_LOGS_TOPIC=${CLASSIFIED_LOGS_TOPIC:-classified-logs}
      - ANOMALIES_TOPIC=${ANOMALIES_TOPIC:-anomalies}
      - SMTP_HOST=${SMTP_HOST}
      - SMTP_PORT=${SMTP_PORT:-587}
      - SMTP_USERNAME=${SMTP_USERNAME}
      - SMTP_PASSWORD=${SMTP_PASSWORD}
      - SMTP_USE_TLS=${SMTP_USE_TLS:-true}
      - EMAIL_FROM=${EMAIL_FROM}
      - EMAIL_RECIPIENTS=${EMAIL_RECIPIENTS}
      - TEAMS_WEBHOOK_URL=${TEAMS_WEBHOOK_URL}
      - ANOMALY_THRESHOLD=${ANOMALY_THRESHOLD:-0.8}
      - DEDUP_WINDOW_MINUTES=${DEDUP_WINDOW_MINUTES:-15}
      - SEND_PREVENTIVE_EMAILS=${SEND_PREVENTIVE_EMAILS:-false}
      - GRAFANA_BASE_URL=${GRAFANA_BASE_URL:-http://localhost:3000}

networks:
  log-streaming:
    driver: bridge

volumes:
  victoria-metrics-data:
  grafana-data:
  ollama-data:
  aws-checkpoints:
  azure-checkpoints: